{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RDcN431I5zC0"
   },
   "source": [
    "# Item-Item Top-N Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MiDyphhp5zC6"
   },
   "source": [
    "In this excercise we will implement a simple top-N recommender, evaluate the algorithms, and then call algorithms from the Surprise package. In top-N recommendations the algorithm is requested to produce a list of N items that the user will be interested in. \n",
    "In this particular execercise we will work with an escape room dataset.\n",
    "\n",
    "First, let's load the dataset, which is already split by time into a training set and a test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CN1l4x4S5zC-"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_set_path = 'resources//train_numerized_with_anon.csv'\n",
    "test_set_path = 'resources//test_numerized_with_anon.csv'\n",
    "\n",
    "train_set = pd.read_csv(train_set_path, parse_dates=[3], index_col='index')\n",
    "test_set = pd.read_csv(test_set_path, parse_dates=[3], index_col='index')\n",
    "\n",
    "users_in_train = train_set.userID.unique()\n",
    "test_set = test_set[test_set.userID.isin(users_in_train)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uou6h0U75zDP"
   },
   "source": [
    "We can take a look at the structure of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mD4Io9UA5zDT",
    "outputId": "8015e618-1b9b-4cc5-a37d-366d3d3e80bf",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>11/11/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>11/11/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>11/11/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>11/11/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>11/11/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>11/11/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>11/11/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>11/11/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>11/11/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>11/11/2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userID  itemID rating   timestamp\n",
       "index                                   \n",
       "0           0       0     10  11/11/2015\n",
       "1           1       0     10  11/11/2015\n",
       "2           2       0      8  11/11/2015\n",
       "3           3       0     10  11/11/2015\n",
       "4           4       0     10  11/11/2015\n",
       "5           5       0     10  11/11/2015\n",
       "6           6       0      5  11/11/2015\n",
       "7           7       0     10  11/11/2015\n",
       "8           8       0     10  11/11/2015\n",
       "9           9       0      9  11/11/2015"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "10    25803\n",
       "9      5131\n",
       "8      4027\n",
       "7      2333\n",
       "6      1162\n",
       "5       574\n",
       "4       319\n",
       "1       244\n",
       "3       237\n",
       "2       192\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "display(train_set.head(10))\n",
    "train_set.rating.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Let's look at the data\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 missing ratings\n",
      "375 different items\n",
      "20197 different users\n"
     ]
    }
   ],
   "source": [
    "# are there missing ratings?\n",
    "print(train_set.rating.isna().sum(), 'missing ratings')\n",
    "\n",
    "# how many different items do we have in the train set?\n",
    "print(len(train_set.itemID.unique()), 'different items')\n",
    "\n",
    "# how many different users?\n",
    "print(len(train_set.userID.unique()), 'different users')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 40022 entries, 0 to 40021\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   userID     40022 non-null  int64 \n",
      " 1   itemID     40022 non-null  int64 \n",
      " 2   rating     40022 non-null  object\n",
      " 3   timestamp  40022 non-null  object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 1.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_set.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "itemID\n",
       "66    741\n",
       "1     601\n",
       "76    548\n",
       "69    547\n",
       "5     512\n",
       "0     510\n",
       "75    504\n",
       "2     501\n",
       "74    458\n",
       "3     455\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_ratings_per_item = train_set.pivot_table(index='itemID', aggfunc='size').sort_values(ascending=False)\n",
    "display(num_ratings_per_item.head(10))\n",
    "num_ratings_per_item.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Aru51gpw5zDh"
   },
   "source": [
    "## Part 1: Recommend Most Popular Items "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A198sQHy5zDk"
   },
   "source": [
    "Now we can begin implementing the our first algorithm, that recommends to the user the list of most popular items. Although this is not a personalized approach, in many cases, this is not a bad idea - popular items are popular because everybody choose them, so there is a high likelihood that recommended popular items will be indeed chosen by the user.\n",
    "\n",
    "In the code below, fill in the missing parts. The algorithm has a training method, where item popularity is computed, and a recommendation method, where the list of popular items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SnPMdrj05zDn"
   },
   "outputs": [],
   "source": [
    "class MostPopular:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.item_ratings_sorted = None\n",
    "        self.train_set = None\n",
    "\n",
    "    def learn_model(self, train_set):\n",
    "        self.train_set = train_set\n",
    "        item_ratings_sorted = self.train_set.groupby('itemID').count().sort_values('rating', ascending=False)\n",
    "        self.item_ratings_sorted = item_ratings_sorted.index.values\n",
    "\n",
    "    def get_top_n_recommendations(self, test_set, top_n):\n",
    "        result = {}\n",
    "        already_ranked_items_by_user = self.train_set.groupby('userID')['itemID'].apply(list)\n",
    "        \n",
    "        # compute recommendations for each user in test set\n",
    "        for userID in test_set.userID.unique():\n",
    "            recommend = [x for x in self.item_ratings_sorted if x not in already_ranked_items_by_user[userID]]\n",
    "            result[str(userID)] = recommend[:top_n]\n",
    "            \n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3ntFJWgb5zDu"
   },
   "source": [
    "Now we can call the most popular algorithm to deliver a list of reocmmendations. The code below prints the list of top 5 recommended items for user with ID 431."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YsnRl1VU5zDw",
    "outputId": "3b1587e7-312d-4050-a656-71ef429fa6b7",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[53, 26, 68, 85, 16]\n"
     ]
    }
   ],
   "source": [
    "popular = MostPopular()\n",
    "popular.learn_model(train_set)\n",
    "popular_recs = popular.get_top_n_recommendations(test_set,top_n=5)\n",
    "print(popular_recs['431'])\n",
    "assert popular_recs['431'] == [53, 26, 68, 85, 16], 'Wrong computation of popular items'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RB9d0u8E5zD6"
   },
   "source": [
    "## Part 2 - Item-Item Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "my9Y885z5zD9"
   },
   "source": [
    "We now learn a slightly more sophisticated model, that uses item-item similarities. Given such a similarity score, we can recommend to a user items that are most similar to the items that the user has chosen in the past. One such useful similarity metric is the Jaccard coefficient. For two items i1 and i2, the Jaccard similarity is the number of users who have chosen both i1 and i2, divided by the number of users who have chosen either i1 or i2. That is, given the list of users who have chosen i1 and the list of users who have chosen i2, the Jaccard similarity is the intersection of the lists, divided by the union of the lists.\n",
    "\n",
    "In practice, to expedite the recommendation process, and hence reduce online latency, we will compute the item-item co-occurence matrix in the model learning phase. Then, online, when recommendations are requested, we only need to compute for each item that the user has already chosen in the past, the Jaccard scores for the other items.\n",
    "\n",
    "As the user has chosen several items in the past, we need to aggregate the Jaccard scores. That is, if the user has previously chosen i1 and i2, item i3 has two scores J(i1,i3) and J(i2,i3), and an aggregation of the scores is needed. There are two popular aggregation functions - sum and max. Empirically, max typically has better perfromance.\n",
    "\n",
    "Fill in the missing parts in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-CfCYaCR5zD-"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import operator\n",
    "from itertools import combinations \n",
    "from math import factorial\n",
    "\n",
    "class Jaccard:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.item_ratings_sorted = None\n",
    "        self.train_set = None\n",
    "        self.item_item_counts = dict()\n",
    "        self.item_counts = None\n",
    "\n",
    "    def learn_model(self, train_set):\n",
    "        print('Started training')\n",
    "        self.train_set = train_set\n",
    "        self.item_counts = self.train_set.groupby('itemID')['userID'].agg('count') #  num users that chose each item\n",
    "                \n",
    "        pbar = tqdm(total = len(train_set.userID.unique()))\n",
    "        \n",
    "        # Iterate over the users, and for each user and each two items that the user chose, increase the count\n",
    "        for user in train_set.userID.unique():\n",
    "            pbar.update(1)\n",
    "\n",
    "            userData = self.train_set[self.train_set.userID == user]            \n",
    "            user_unique_items = userData.itemID.tolist()\n",
    "            \n",
    "            # find all unique pairs of items the user chose\n",
    "            unique_pairs = list(combinations(user_unique_items, 2))\n",
    "            \n",
    "            # increase count of pair in dictionary\n",
    "            for (item1, item2) in unique_pairs:\n",
    "                if (item1, item2) in self.item_item_counts:\n",
    "                    self.item_item_counts[(item1, item2)] += 1\n",
    "                elif (item2, item1) in self.item_item_counts:\n",
    "                    self.item_item_counts[(item2, item1)] += 1\n",
    "                else:\n",
    "                    self.item_item_counts[(item1, item2)] = 1\n",
    "                        \n",
    "        pbar.close()\n",
    "        print('Done training')            \n",
    "            \n",
    "\n",
    "    def get_top_n_recommendations(self, test_set, top_n):\n",
    "        print('Started computing recommendations')\n",
    "        result = {}\n",
    "        already_ranked_items_by_users = self.train_set.groupby('userID')['itemID'].apply(list)\n",
    "        \n",
    "        pbar = tqdm(total=len(test_set.userID.unique()))\n",
    "                \n",
    "        #For each user in the test set compute recommendations\n",
    "        for i, userID in enumerate(test_set.userID.unique()):\n",
    "            if i % 20 == 0:\n",
    "                pbar.update(20)\n",
    "            \n",
    "            result[str(userID)] = []\n",
    "            maxvalues = dict()  # maintain for each potential item to recommend its highest Jaccard score\n",
    "                        \n",
    "            # find all items the user hasn't chosen (all items minus the one he ranked)\n",
    "            items_user_did_not_rank = set(self.train_set.itemID.unique()) - set(already_ranked_items_by_users[userID])\n",
    "            \n",
    "            # Go over every ranked item\n",
    "            for item in already_ranked_items_by_users[userID]:\n",
    "                for unranked_item in items_user_did_not_rank:\n",
    "                    \n",
    "                    # Find how many users chose both items from self.item_item_counts\n",
    "                    if (item, unranked_item) in self.item_item_counts.keys():\n",
    "                        chose_both  = self.item_item_counts[(item, unranked_item)]\n",
    "                    elif (unranked_item, item) in self.item_item_counts.keys():\n",
    "                        chose_both = self.item_item_counts[(unranked_item, item)]\n",
    "                    else:\n",
    "                        chose_both = 0\n",
    "                    \n",
    "                    jaccard_score = chose_both / (self.item_counts[item] + self.item_counts[unranked_item] - chose_both)\n",
    "            \n",
    "                    # update maxvalues\n",
    "                    if unranked_item in maxvalues.keys():\n",
    "                        if jaccard_score >  maxvalues[unranked_item]:\n",
    "                            maxvalues[unranked_item] = jaccard_score\n",
    "                    else:\n",
    "                        maxvalues[unranked_item] = jaccard_score\n",
    "            \n",
    "            #Now we just take the top N items by decreasing Jaccard\n",
    "            top_list = sorted(maxvalues.items(), key=lambda kv : -kv[1])\n",
    "            i=0\n",
    "            j=0\n",
    "            while i < top_n and j < len(top_list):\n",
    "                itemID = top_list[j][0]\n",
    "                j = j + 1\n",
    "                result[str(userID)].append(itemID)\n",
    "                i = i + 1\n",
    "            \n",
    "        pbar.close()\n",
    "        print('Done computing recommendations')\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "qa-ZrkOT5zEF"
   },
   "source": [
    "The code below trains a Jaccard model and generates recommendations. Training will take a while, as we need to iterate over all users, and for each user go over her items in quadratic time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gpP9JFqj5zEH",
    "outputId": "45ba9eac-58ee-45f8-dcab-dac1686ec115",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 199/20197 [00:00<00:10, 1984.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20197/20197 [00:09<00:00, 2037.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training\n",
      "Started computing recommendations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "240it [00:09, 24.04it/s]                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done computing recommendations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "jaccard = Jaccard()\n",
    "jaccard.learn_model(train_set)\n",
    "jaccard_recs = jaccard.get_top_n_recommendations(test_set,top_n=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1hhkOlW65zEP"
   },
   "source": [
    "As a side note - as computing the ite-item counts takes a while (especially with Python), we are using here the progress bar from the tqdm package (https://pypi.org/project/tqdm/). You need to install tqdm, or remove the progress bar, which would of course is not needed for the algorithm to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bESNd1ce5zEW"
   },
   "source": [
    "We now want to compare the recommendation lists to see which one is better. In top-N recommendations it is popular to computer the Precision@N metric - the portion of recommended items that were chosen by users in the test set. This is typically a reasonable metric for real systems, where one wants to optimize the number of recommended items that are chosen.\n",
    "\n",
    "We compute Precision@N by comparing the number of recommendations chosen by the users, divided by the number of overall recommendations.\n",
    "\n",
    "Fill in the missing parts in the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PbfW_Hv25zEY"
   },
   "outputs": [],
   "source": [
    "def compute_precision(test_set, recommendations):\n",
    "   \n",
    "    hits = 0     #hits is the number of items that were recommended and chosen\n",
    "    recs = 0     #recs is the total number of recommended items\n",
    "    \n",
    "    for u in test_set.userID.unique():\n",
    "        userData = test_set[test_set.userID == u]\n",
    "        userRecs = recommendations.get(str(u))\n",
    "        chosen_by_user = userData['itemID'].values\n",
    "        \n",
    "        recs += len(userRecs)\n",
    "        hits+=len(set(chosen_by_user).intersection(set(userRecs)))\n",
    "        \n",
    "    return hits / recs\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-AJvW67S5zEe",
    "outputId": "17e4b0ff-5e0b-49d9-de38-1cdd2101bf61",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard= 0.03700440528634361   Popularity= 0.027312775330396475\n"
     ]
    }
   ],
   "source": [
    "p1 = compute_precision(test_set, jaccard_recs)\n",
    "p2 = compute_precision(test_set, popular_recs)\n",
    "print(\"Jaccard=\", p1, \"  Popularity=\", p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6SXmVklZ5zEm"
   },
   "source": [
    "The precision values for this dataset may seem pretty low, but this is typical for many top-N problems. It is important not to compute metrics that hide the true values, such as AUC, but to acknowledge the perfromance of the system in the application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j84r4jBp5zEp"
   },
   "source": [
    "## Part 4 - Calling Algorithms from the Surprise Package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "mXS50Vnj5zEs"
   },
   "source": [
    "There are many existing recommendation algorithms available. We will now see how we can call algorithms from the Surprise package. \n",
    "\n",
    "The code below adds a wrapper around the algorithm to transform the resulting recommendations into our desired format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i7vTBSmw5zEs"
   },
   "source": [
    "#### NOTE: \n",
    "To run the code below you first have to install _surprise_ (http://surpriselib.com/). surprise requires scipy >=1.0, so update if needed.\n",
    "\n",
    "To install: pip install scikit-surprise or, if you're using anaconda:  conda install -c conda-forge scikit-surprise).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bnOWlz-m5zEv"
   },
   "outputs": [],
   "source": [
    "import sys, string, os\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import operator\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import PredefinedKFold\n",
    "from surprise.prediction_algorithms import *\n",
    "\n",
    "\n",
    "class SurpriseRecMethod():\n",
    "\n",
    "    #method will be the specific Surprise algorithm that we will call\n",
    "    def __init__(self, method):\n",
    "        self.method = method\n",
    "\n",
    "    def fit(self, train_set):\n",
    "        self.train_set = train_set\n",
    "\n",
    "\n",
    "    def get_top_n_recommendations(self, test_set, top_n):\n",
    "        self.test_set = test_set\n",
    "\n",
    "        #Surprise requires a slightly different input data format, so we use two different CSVs\n",
    "        test_path_tmp = \"resources//test_file.csv\"\n",
    "        train_path_tmp = \"resources//train_file.csv\"\n",
    "\n",
    "        self.train_set.to_csv(train_path_tmp, index=False, header=False)\n",
    "        self.test_set.to_csv(test_path_tmp, index=False, header=False)\n",
    "\n",
    "        fold_files = [(train_path_tmp, test_path_tmp)]\n",
    "        reader = Reader(rating_scale=(1, 10), line_format='user item rating', sep=',')\n",
    "        data = Dataset.load_from_folds(fold_files, reader=reader)\n",
    "\n",
    "        for trainset, testset in PredefinedKFold().split(data):\n",
    "            self.method.fit(trainset)\n",
    "\n",
    "        already_ranked_items_by_users = self.train_set.groupby('userID')['itemID'].apply(list)\n",
    "\n",
    "        recommendations = {}\n",
    "        pbar = tqdm(total=len(self.test_set.userID.unique()))\n",
    "        for userID in self.test_set.userID.unique():\n",
    "            pbar.update(1)\n",
    "\n",
    "            if userID not in self.train_set.userID.unique():\n",
    "                recommendations[str(userID)] = []\n",
    "                continue\n",
    "\n",
    "            items_expected_ranking = {}\n",
    "            for itemID in self.train_set.itemID.unique():\n",
    "                if itemID in already_ranked_items_by_users[userID]:\n",
    "                    continue\n",
    "                #We call here the specific Surprise method that we use for this model\n",
    "                #The method predicts a score for a given item\n",
    "                predicted = self.method.predict(str(userID), str(itemID), clip=False)\n",
    "                items_expected_ranking[itemID] = predicted[3]\n",
    "                \n",
    "            #Now we just sort by decreasing scores and take the top N\n",
    "            sorted_predictions = sorted(items_expected_ranking.items(), key=operator.itemgetter(1))\n",
    "            sorted_predictions.reverse()\n",
    "            sorted_predictions = [x[0] for x in sorted_predictions]\n",
    "            user_recommendations = sorted_predictions[:top_n]\n",
    "            recommendations[str(userID)] = user_recommendations\n",
    "        pbar.close()\n",
    "        return recommendations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3YIHU4ZL5zE5"
   },
   "source": [
    "The code below calls the package with the SlopeOne algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vsXXqfoD5zE6",
    "outputId": "6ddbe18f-7994-4c6f-828b-4ee51ee0e9e8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [00:01<00:00, 134.47it/s]\n"
     ]
    }
   ],
   "source": [
    "modelSlopeOne = SurpriseRecMethod(SlopeOne())\n",
    "modelSlopeOne.fit(train_set)\n",
    "recSlopeOne = modelSlopeOne.get_top_n_recommendations(test_set, 5)\n",
    "p3 = compute_precision(test_set,recSlopeOne)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-4UeYiqg5zFE"
   },
   "source": [
    "The code below calls the package with a nearest neighbor user-item recommendation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "up4c0wqr5zFH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [00:06<00:00, 35.55it/s]\n"
     ]
    }
   ],
   "source": [
    "modelKNNUser = SurpriseRecMethod(KNNBasic(sim_options={'name': 'cosine', 'user_based': True}, random_state = 42))\n",
    "modelKNNUser.fit(train_set)\n",
    "recKNNUser = modelKNNUser.get_top_n_recommendations(test_set, 5)\n",
    "p4 = compute_precision(test_set,recKNNUser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e-FDg7Sk5zFP"
   },
   "source": [
    "Let us look at the results of all algorithms together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MOrBFXVN5zFR"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Jaccard</th>\n",
       "      <td>0.037004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Popularity</th>\n",
       "      <td>0.027313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SlopeOne</th>\n",
       "      <td>0.032599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User KNN</th>\n",
       "      <td>0.075771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Precision\n",
       "Jaccard      0.037004\n",
       "Popularity   0.027313\n",
       "SlopeOne     0.032599\n",
       "User KNN     0.075771"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict({'Jaccard':p1,'Popularity':p2,'SlopeOne':p3,'User KNN':p4}, orient='index',columns=['Precision'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y9-JSGCE5zFY"
   },
   "source": [
    "Try the NMF (non-negative matrix factorization) algorithms from the package - https://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.NMF.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [00:01<00:00, 206.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03700440528634361\n"
     ]
    }
   ],
   "source": [
    "# NMF with default parameters\n",
    "\n",
    "modelNMFUser = SurpriseRecMethod(NMF(random_state = 42))\n",
    "modelNMFUser.fit(train_set)\n",
    "recNMFUser = modelNMFUser.get_top_n_recommendations(test_set, 5)\n",
    "p5 = compute_precision(test_set,recNMFUser)\n",
    "print(p5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "let's try to improve NMF by tuning some hyper-paramters\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5198/5198 [00:08<00:00, 591.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 factors, percision = 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5198/5198 [00:08<00:00, 582.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 factors, percision = 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5198/5198 [00:08<00:00, 587.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 factors, percision = 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5198/5198 [00:08<00:00, 583.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 factors, percision = 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5198/5198 [00:08<00:00, 584.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 factors, percision = 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5198/5198 [00:08<00:00, 578.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 factors, percision = 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5198/5198 [00:08<00:00, 582.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 factors, percision = 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5198/5198 [00:08<00:00, 587.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 factors, percision = 0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5198/5198 [00:08<00:00, 581.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 factors, percision = 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5198/5198 [00:08<00:00, 581.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 factors, percision = 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5198/5198 [00:08<00:00, 581.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 factors, percision = 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5198/5198 [00:08<00:00, 581.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 factors, percision = 0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5198/5198 [00:08<00:00, 581.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 factors, percision = 0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5198/5198 [00:08<00:00, 579.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 factors, percision = 0.004\n",
      "best results using 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x124a620f0>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's split the train data to train and cross validation so we can adjust the hyper-parameters\n",
    "\n",
    "mask = np.random.rand(len(train_set)) < 0.8\n",
    "train_ = train_set[mask]\n",
    "cv_ = train_set[~mask]\n",
    "\n",
    "percision_vec = []\n",
    "\n",
    "factors = range(2,16)\n",
    "for i in factors:\n",
    "    modelNMFUser = SurpriseRecMethod(NMF(n_factors=i, biased = True, random_state = 42))\n",
    "    modelNMFUser.fit(train_)\n",
    "    recNMFUser = modelNMFUser.get_top_n_recommendations(cv_, 5)\n",
    "    perc = compute_precision(cv_,recNMFUser)\n",
    "    print(f'{i} factors, percision = {perc:.3f}') \n",
    "    percision_vec.append(perc)\n",
    "    \n",
    "    \n",
    "best_factor = factors[np.argmax(percision_vec)]\n",
    "print('best results using', best_factor)\n",
    "\n",
    "plt.plot(factors, percision_vec)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Let's use the best n_factors and use it \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IfHe-_iB5zFZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [00:01<00:00, 186.77it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "modelNMFUser = SurpriseRecMethod(NMF(n_factors = best_factor, biased = True, random_state = 42))\n",
    "modelNMFUser.fit(train_set)\n",
    "recNMFUser = modelNMFUser.get_top_n_recommendations(test_set, 5)\n",
    "p5 = compute_precision(test_set,recNMFUser)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Jaccard</th>\n",
       "      <td>0.037004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Popularity</th>\n",
       "      <td>0.027313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SlopeOne</th>\n",
       "      <td>0.032599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User KNN</th>\n",
       "      <td>0.075771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMF</th>\n",
       "      <td>0.055507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Precision\n",
       "Jaccard      0.037004\n",
       "Popularity   0.027313\n",
       "SlopeOne     0.032599\n",
       "User KNN     0.075771\n",
       "NMF          0.055507"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict({'Jaccard':p1,'Popularity':p2,'SlopeOne':p3,'User KNN':p4, 'NMF':p5}, orient='index',columns=['Precision'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "We can see the tuned version of NMF has higher accuracy than the default one, but it's still not as good as user KNN.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wPSTAFb15zFf"
   },
   "source": [
    "For this particular dataset, the user nearest neighbor approach worked best. Hence, should we need to choose a method to put online, we should go with this method."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "ExcerciseTopN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
